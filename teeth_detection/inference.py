import numpy as np
from typing import Dict, Any, List
from ultralytics import YOLO
import cv2
from .preprocessing import TeethImagePreprocessor
from .postprocessing import TeethDetectionPostprocessor

class TeethDetectionInference:
    """ç‰™é½¿æ£€æµ‹æ¨ç†ç±»"""
    
    def __init__(self, model_path: str, confidence_threshold: float = 0.5):
        self.model_path = model_path
        self.confidence_threshold = confidence_threshold
        self.model = None
        self.preprocessor = TeethImagePreprocessor()
        self.postprocessor = TeethDetectionPostprocessor(confidence_threshold)
        
    def load_model(self):
        """åŠ è½½YOLOv8æ¨¡å‹"""
        try:
            self.model = YOLO(self.model_path)
            print(f"âœ… YOLOv8æ¨¡å‹åŠ è½½æˆåŠŸ: {self.model_path}")
            return True
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
            return False
    
    def predict(self, image_data: bytes) -> Dict[str, Any]:
        """æ‰§è¡Œå®Œæ•´çš„ç‰™é½¿æ£€æµ‹æ¨ç†"""
        if self.model is None:
            if not self.load_model():
                return {'error': 'æ¨¡å‹åŠ è½½å¤±è´¥'}
        
        try:
            # é¢„å¤„ç†
            processed_image, preprocess_info = self.preprocessor.preprocess(image_data)
            
            # æ¨¡å‹æ¨ç†
            results = self.model(processed_image, conf=self.confidence_threshold, verbose=False)
            
            # è§£æåŸå§‹æ£€æµ‹ç»“æœ
            raw_detections = self._parse_yolo_results(results, preprocess_info)
            
            # åå¤„ç†
            final_result = self.postprocessor.postprocess(
                raw_detections, preprocess_info['original_shape']
            )
            
            # æ·»åŠ é¢„å¤„ç†ä¿¡æ¯
            final_result['preprocess_info'] = preprocess_info
            
            return final_result
            
        except Exception as e:
            return {'error': f'æ¨ç†å¤±è´¥: {str(e)}'}
    
    def _parse_yolo_results(self, results, preprocess_info: Dict[str, Any]) -> List[Dict[str, Any]]:
        """è§£æYOLOæ¨¡å‹è¾“å‡ºç»“æœ"""
        raw_detections = []
        
        if not results or len(results) == 0:
            return raw_detections
        
        # è·å–ç¬¬ä¸€ä¸ªç»“æœï¼ˆå•å¼ å›¾åƒï¼‰
        result = results[0]
        
        if result.boxes is None:
            return raw_detections
        
        # è·å–æ£€æµ‹æ¡†ä¿¡æ¯
        boxes = result.boxes.xyxy.cpu().numpy()  # è¾¹ç•Œæ¡†åæ ‡
        confidences = result.boxes.conf.cpu().numpy()  # ç½®ä¿¡åº¦
        class_ids = result.boxes.cls.cpu().numpy()  # ç±»åˆ«ID
        
        for i in range(len(boxes)):
            # è½¬æ¢ä¸ºæ•´æ•°åæ ‡
            x1, y1, x2, y2 = boxes[i].astype(int)
            confidence = float(confidences[i])
            class_id = int(class_ids[i])
            
            # è·å–ç±»åˆ«åç§°
            class_name = self._get_class_name(class_id)
            
            raw_detections.append({
                'bbox': [x1, y1, x2, y2],
                'confidence': confidence,
                'class_id': class_id,
                'class_name': class_name
            })
        
        return raw_detections
    
    def _get_class_name(self, class_id: int) -> str:
        """æ ¹æ®ç±»åˆ«IDè·å–ç±»åˆ«åç§°"""
        # YOLOv8ç‰™é½¿æ£€æµ‹æ¨¡å‹çš„ç±»åˆ«æ˜ å°„
        class_names = {
            0: 'tooth',      # ç‰™é½¿
            1: 'caries',     # é¾‹é½¿
            2: 'plaque',     # ç‰™èŒæ–‘
            3: 'gingivitis'  # ç‰™é¾ˆç‚
        }
        return class_names.get(class_id, f'class_{class_id}')
    
    def visualize_detections(self, image_data: bytes, detections: List[Dict[str, Any]]) -> bytes:
        """å¯è§†åŒ–æ£€æµ‹ç»“æœå¹¶è¿”å›å›¾åƒå­—èŠ‚æ•°æ®"""
        # åŠ è½½åŸå§‹å›¾åƒ
        image = cv2.imdecode(np.frombuffer(image_data, np.uint8), cv2.IMREAD_COLOR)
        
        # ç»˜åˆ¶æ£€æµ‹æ¡†
        for det in detections:
            x1, y1, x2, y2 = map(int, det['bbox'])
            confidence = det['confidence']
            class_name = det['class_name']
            
            # ç»˜åˆ¶è¾¹ç•Œæ¡†
            color = self._get_class_color(class_name)
            cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)
            
            # ç»˜åˆ¶æ ‡ç­¾
            label = f"{class_name}: {confidence:.2f}"
            cv2.putText(image, label, (x1, y1 - 10), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)
        
        # è½¬æ¢ä¸ºå­—èŠ‚æ•°æ®
        success, encoded_image = cv2.imencode('.jpg', image)
        if not success:
            raise ValueError("æ— æ³•ç¼–ç å¯è§†åŒ–å›¾åƒ")
        
        return encoded_image.tobytes()
    
    def _get_class_color(self, class_name: str) -> tuple:
        """æ ¹æ®ç±»åˆ«åç§°è·å–é¢œè‰²"""
        colors = {
            'tooth': (0, 255, 0),      # ç»¿è‰² - ç‰™é½¿
            'caries': (0, 0, 255),     # çº¢è‰² - é¾‹é½¿
            'plaque': (255, 255, 0),   # é»„è‰² - ç‰™èŒæ–‘
            'gingivitis': (255, 0, 0)  # è“è‰² - ç‰™é¾ˆç‚
        }
        return colors.get(class_name, (255, 255, 255))  # é»˜è®¤ç™½è‰²
    
    def batch_predict(self, image_data_list: List[bytes]) -> List[Dict[str, Any]]:
        """æ‰¹é‡é¢„æµ‹å¤šå¼ å›¾åƒ"""
        results = []
        for image_data in image_data_list:
            results.append(self.predict(image_data))
        return results

# æµ‹è¯•æ¨ç†æµç¨‹
if __name__ == "__main__":
    # åˆå§‹åŒ–æ¨ç†å™¨
    detector = TeethDetectionInference(
        model_path="models/yolov8n-seg.pt",  # ä½¿ç”¨è¾ƒå°çš„æ¨¡å‹è¿›è¡Œæµ‹è¯•
        confidence_threshold=0.5
    )
    
    # åˆ›å»ºæµ‹è¯•å›¾åƒ
    from preprocessing import create_sample_teeth_image
    test_image_data = create_sample_teeth_image()
    
    # æ‰§è¡Œæ¨ç†
    print("ğŸ§ª æµ‹è¯•ç‰™é½¿æ£€æµ‹æ¨ç†...")
    result = detector.predict(test_image_data)
    
    if 'error' in result:
        print(f"âŒ æ¨ç†å¤±è´¥: {result['error']}")
    else:
        print("âœ… æ¨ç†æˆåŠŸ!")
        print(f"æ£€æµ‹åˆ°ç‰™é½¿æ•°: {result['total_teeth_detected']}")
        print(f"è¦†ç›–ç‡: {result['coverage_percentage']:.1f}%")
        print(f"ç‰™é½¿åˆ†å¸ƒ: {result['tooth_distribution']}")
        
        # å¯è§†åŒ–ç»“æœ
        try:
            visualized_image = detector.visualize_detections(test_image_data, result['detections'])
            print("âœ… å¯è§†åŒ–å›¾åƒç”ŸæˆæˆåŠŸ")
            
            # ä¿å­˜å¯è§†åŒ–ç»“æœï¼ˆå¯é€‰ï¼‰
            with open('test_detection_result.jpg', 'wb') as f:
                f.write(visualized_image)
            print("ğŸ“ å¯è§†åŒ–ç»“æœå·²ä¿å­˜ä¸º test_detection_result.jpg")
            
        except Exception as e:
            print(f"âŒ å¯è§†åŒ–å¤±è´¥: {str(e)}")